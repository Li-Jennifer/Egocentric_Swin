{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c814f683-474e-4604-bd05-c2549958a48c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/mmaction2\n"
     ]
    }
   ],
   "source": [
    "%cd ../mmaction2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fe45f11-e6d3-4fdd-b5f6-86e73bb9e287",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./configs/egocentric/slowfast_fpha.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./configs/egocentric/slowfast_fpha.py\n",
    "\n",
    "#dataset\n",
    "dataset_type = 'VideoDataset'\n",
    "data_root = 'data/video_fpha/train'\n",
    "data_root_val = 'data/video_fpha/val'\n",
    "ann_file_train = 'data/video_fpha/fpha_train.txt'\n",
    "ann_file_val = 'data/video_fpha/fpha_val.txt'\n",
    "ann_file_test = 'data/video_fpha/fpha_val.txt'\n",
    "\n",
    "#hooks\n",
    "default_hooks = dict(\n",
    "    checkpoint=dict(\n",
    "        interval=4, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
    "    logger=dict(ignore_last=False, interval=100, type='LoggerHook'),\n",
    "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
    "    runtime_info=dict(type='RuntimeInfoHook'),\n",
    "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
    "    sync_buffers=dict(type='SyncBuffersHook'),\n",
    "    timer=dict(type='IterTimerHook'))\n",
    "default_scope = 'mmaction'\n",
    "#env\n",
    "env_cfg = dict(\n",
    "    cudnn_benchmark=False,\n",
    "    dist_cfg=dict(backend='nccl'),\n",
    "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
    "file_client_args = dict(io_backend='disk')\n",
    "launcher = 'none'\n",
    "load_from = './checkpoints/slowfast_fpha.pth'\n",
    "log_level = 'INFO'\n",
    "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
    "#model\n",
    "model = dict(\n",
    "    backbone=dict(\n",
    "        channel_ratio=8,\n",
    "        fast_pathway=dict(\n",
    "            base_channels=8,\n",
    "            conv1_kernel=(\n",
    "                5,\n",
    "                7,\n",
    "                7,\n",
    "            ),\n",
    "            conv1_stride_t=1,\n",
    "            depth=50,\n",
    "            lateral=False,\n",
    "            norm_eval=False,\n",
    "            pool1_stride_t=1,\n",
    "            pretrained=None,\n",
    "            type='resnet3d'),\n",
    "        pretrained=None,\n",
    "        resample_rate=8,\n",
    "        slow_pathway=dict(\n",
    "            conv1_kernel=(\n",
    "                1,\n",
    "                7,\n",
    "                7,\n",
    "            ),\n",
    "            conv1_stride_t=1,\n",
    "            depth=50,\n",
    "            dilations=(\n",
    "                1,\n",
    "                1,\n",
    "                1,\n",
    "                1,\n",
    "            ),\n",
    "            inflate=(\n",
    "                0,\n",
    "                0,\n",
    "                1,\n",
    "                1,\n",
    "            ),\n",
    "            lateral=True,\n",
    "            norm_eval=False,\n",
    "            pool1_stride_t=1,\n",
    "            pretrained=None,\n",
    "            type='resnet3d'),\n",
    "        speed_ratio=8,\n",
    "        type='ResNet3dSlowFast'),\n",
    "    cls_head=dict(\n",
    "        average_clips='prob',\n",
    "        dropout_ratio=0.5,\n",
    "        in_channels=2304,\n",
    "        num_classes=46, #classes+1\n",
    "        spatial_type='avg',\n",
    "        type='SlowFastHead'),\n",
    "    data_preprocessor=dict(\n",
    "        format_shape='NCTHW',\n",
    "        mean=[\n",
    "            123.675,\n",
    "            116.28,\n",
    "            103.53,\n",
    "        ],\n",
    "        std=[\n",
    "            58.395,\n",
    "            57.12,\n",
    "            57.375,\n",
    "        ],\n",
    "        type='ActionDataPreprocessor'),\n",
    "    type='Recognizer3D')\n",
    "#optim\n",
    "optim_wrapper = dict(\n",
    "    clip_grad=dict(max_norm=40, norm_type=2),\n",
    "    optimizer=dict(lr=0.1, momentum=0.9, type='SGD', weight_decay=0.0001))\n",
    "#param\n",
    "param_scheduler = [\n",
    "    dict(\n",
    "        begin=0,\n",
    "        by_epoch=True,\n",
    "        convert_to_iter_based=True,\n",
    "        end=34,\n",
    "        start_factor=0.1,\n",
    "        type='LinearLR'),\n",
    "    dict(\n",
    "        T_max=256,\n",
    "        begin=0,\n",
    "        by_epoch=True,\n",
    "        end=256,\n",
    "        eta_min=0,\n",
    "        type='CosineAnnealingLR'),\n",
    "]\n",
    "randomness = dict(deterministic=False, diff_rank_seed=False, seed=None)\n",
    "resume = False\n",
    "#test\n",
    "test_cfg = dict(type='TestLoop')\n",
    "test_dataloader = dict(\n",
    "    batch_size=1,\n",
    "    dataset=dict(\n",
    "        ann_file='data/video_fpha/fpha_val.txt',\n",
    "        data_prefix=dict(video='data/video_fpha/val'),\n",
    "        pipeline=[\n",
    "            dict(io_backend='disk', type='DecordInit'),\n",
    "            dict(\n",
    "                clip_len=32,\n",
    "                frame_interval=2,\n",
    "                num_clips=10,\n",
    "                test_mode=True,\n",
    "                type='SampleFrames'),\n",
    "            dict(type='DecordDecode'),\n",
    "            dict(scale=(\n",
    "                -1,\n",
    "                256,\n",
    "            ), type='Resize'),\n",
    "            dict(crop_size=256, type='ThreeCrop'),\n",
    "            dict(input_format='NCTHW', type='FormatShape'),\n",
    "            dict(type='PackActionInputs'),\n",
    "        ],\n",
    "        test_mode=True,\n",
    "        type='VideoDataset'),\n",
    "    num_workers=8,\n",
    "    persistent_workers=True,\n",
    "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
    "test_evaluator = dict(type='AccMetric')\n",
    "test_pipeline = [\n",
    "    dict(io_backend='disk', type='DecordInit'),\n",
    "    dict(\n",
    "        clip_len=32,\n",
    "        frame_interval=2,\n",
    "        num_clips=10,\n",
    "        test_mode=True,\n",
    "        type='SampleFrames'),\n",
    "    dict(type='DecordDecode'),\n",
    "    dict(scale=(\n",
    "        -1,\n",
    "        256,\n",
    "    ), type='Resize'),\n",
    "    dict(crop_size=256, type='ThreeCrop'),\n",
    "    dict(input_format='NCTHW', type='FormatShape'),\n",
    "    dict(type='PackActionInputs'),\n",
    "]\n",
    "#train\n",
    "train_cfg = dict( #max_epochs\n",
    "    max_epochs=256, type='EpochBasedTrainLoop', val_begin=1, val_interval=5)\n",
    "train_dataloader = dict(\n",
    "    batch_size=8,\n",
    "    dataset=dict(\n",
    "        ann_file='data/video_fpha/fpha_train.txt',\n",
    "        data_prefix=dict(video='data/video_fpha/train'),\n",
    "        pipeline=[\n",
    "            dict(io_backend='disk', type='DecordInit'),\n",
    "            dict(\n",
    "                clip_len=32,\n",
    "                frame_interval=2,\n",
    "                num_clips=1,\n",
    "                type='SampleFrames'),\n",
    "            dict(type='DecordDecode'),\n",
    "            dict(scale=(\n",
    "                -1,\n",
    "                256,\n",
    "            ), type='Resize'),\n",
    "            dict(type='RandomResizedCrop'),\n",
    "            dict(keep_ratio=False, scale=(\n",
    "                224,\n",
    "                224,\n",
    "            ), type='Resize'),\n",
    "            dict(flip_ratio=0.5, type='Flip'),\n",
    "            dict(input_format='NCTHW', type='FormatShape'),\n",
    "            dict(type='PackActionInputs'),\n",
    "        ],\n",
    "        type='VideoDataset'),\n",
    "    num_workers=8,\n",
    "    persistent_workers=True,\n",
    "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
    "train_pipeline = [\n",
    "    dict(io_backend='disk', type='DecordInit'),\n",
    "    dict(clip_len=32, frame_interval=2, num_clips=1, type='SampleFrames'),\n",
    "    dict(type='DecordDecode'),\n",
    "    dict(scale=(\n",
    "        -1,\n",
    "        256,\n",
    "    ), type='Resize'),\n",
    "    dict(type='RandomResizedCrop'),\n",
    "    dict(keep_ratio=False, scale=(\n",
    "        224,\n",
    "        224,\n",
    "    ), type='Resize'),\n",
    "    dict(flip_ratio=0.5, type='Flip'),\n",
    "    dict(input_format='NCTHW', type='FormatShape'),\n",
    "    dict(type='PackActionInputs'),\n",
    "]\n",
    "#val\n",
    "val_cfg = dict(type='ValLoop')\n",
    "val_dataloader = dict(\n",
    "    batch_size=8,\n",
    "    dataset=dict(\n",
    "        ann_file='data/video_fpha/fpha_val.txt',\n",
    "        data_prefix=dict(video='data/video_fpha/val'),\n",
    "        pipeline=[\n",
    "            dict(io_backend='disk', type='DecordInit'),\n",
    "            dict(\n",
    "                clip_len=32,\n",
    "                frame_interval=2,\n",
    "                num_clips=1,\n",
    "                test_mode=True,\n",
    "                type='SampleFrames'),\n",
    "            dict(type='DecordDecode'),\n",
    "            dict(scale=(\n",
    "                -1,\n",
    "                256,\n",
    "            ), type='Resize'),\n",
    "            dict(crop_size=224, type='CenterCrop'),\n",
    "            dict(input_format='NCTHW', type='FormatShape'),\n",
    "            dict(type='PackActionInputs'),\n",
    "        ],\n",
    "        test_mode=True,\n",
    "        type='VideoDataset'),\n",
    "    num_workers=8,\n",
    "    persistent_workers=True,\n",
    "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
    "val_evaluator = dict(type='AccMetric')\n",
    "val_pipeline = [\n",
    "    dict(io_backend='disk', type='DecordInit'),\n",
    "    dict(\n",
    "        clip_len=32,\n",
    "        frame_interval=2,\n",
    "        num_clips=1,\n",
    "        test_mode=True,\n",
    "        type='SampleFrames'),\n",
    "    dict(type='DecordDecode'),\n",
    "    dict(scale=(\n",
    "        -1,\n",
    "        256,\n",
    "    ), type='Resize'),\n",
    "    dict(crop_size=224, type='CenterCrop'),\n",
    "    dict(input_format='NCTHW', type='FormatShape'),\n",
    "    dict(type='PackActionInputs'),\n",
    "]\n",
    "vis_backends = [\n",
    "    dict(type='LocalVisBackend'),\n",
    "]\n",
    "visualizer = dict(\n",
    "    type='ActionVisualizer', vis_backends=[\n",
    "        dict(type='LocalVisBackend'),\n",
    "    ])\n",
    "work_dir = './work_dirs/slowfast_fpha'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efae5b1b-66f9-4479-bc13-1287006a91bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/06 08:26:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 509387482\n",
      "    GPU 0: NVIDIA GeForce RTX 3090\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
      "    PyTorch: 2.0.0+cu118\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.1+cu118\n",
      "    OpenCV: 4.8.0\n",
      "    MMEngine: 0.8.4\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    deterministic: False\n",
      "    diff_rank_seed: False\n",
      "    seed: 509387482\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "08/06 08:26:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "ann_file_test = 'data/video_fpha/fpha_val.txt'\n",
      "ann_file_train = 'data/video_fpha/fpha_train.txt'\n",
      "ann_file_val = 'data/video_fpha/fpha_val.txt'\n",
      "data_root = 'data/video_fpha/train'\n",
      "data_root_val = 'data/video_fpha/val'\n",
      "dataset_type = 'VideoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        interval=4, max_keep_ckpts=2, save_best='auto', type='CheckpointHook'),\n",
      "    logger=dict(ignore_last=False, interval=100, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    runtime_info=dict(type='RuntimeInfoHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffers=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'))\n",
      "default_scope = 'mmaction'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "file_client_args = dict(io_backend='disk')\n",
      "launcher = 'none'\n",
      "load_from = './checkpoints/slowfast_fpha.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        channel_ratio=8,\n",
      "        fast_pathway=dict(\n",
      "            base_channels=8,\n",
      "            conv1_kernel=(\n",
      "                5,\n",
      "                7,\n",
      "                7,\n",
      "            ),\n",
      "            conv1_stride_t=1,\n",
      "            depth=50,\n",
      "            lateral=False,\n",
      "            norm_eval=False,\n",
      "            pool1_stride_t=1,\n",
      "            pretrained=None,\n",
      "            type='resnet3d'),\n",
      "        pretrained=None,\n",
      "        resample_rate=8,\n",
      "        slow_pathway=dict(\n",
      "            conv1_kernel=(\n",
      "                1,\n",
      "                7,\n",
      "                7,\n",
      "            ),\n",
      "            conv1_stride_t=1,\n",
      "            depth=50,\n",
      "            dilations=(\n",
      "                1,\n",
      "                1,\n",
      "                1,\n",
      "                1,\n",
      "            ),\n",
      "            inflate=(\n",
      "                0,\n",
      "                0,\n",
      "                1,\n",
      "                1,\n",
      "            ),\n",
      "            lateral=True,\n",
      "            norm_eval=False,\n",
      "            pool1_stride_t=1,\n",
      "            pretrained=None,\n",
      "            type='resnet3d'),\n",
      "        speed_ratio=8,\n",
      "        type='ResNet3dSlowFast'),\n",
      "    cls_head=dict(\n",
      "        average_clips='prob',\n",
      "        dropout_ratio=0.5,\n",
      "        in_channels=2304,\n",
      "        num_classes=46,\n",
      "        spatial_type='avg',\n",
      "        type='SlowFastHead'),\n",
      "    data_preprocessor=dict(\n",
      "        format_shape='NCTHW',\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='ActionDataPreprocessor'),\n",
      "    type='Recognizer3D')\n",
      "num_classes = 46\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=dict(max_norm=40, norm_type=2),\n",
      "    optimizer=dict(lr=0.1, momentum=0.9, type='SGD', weight_decay=0.0001))\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        convert_to_iter_based=True,\n",
      "        end=34,\n",
      "        start_factor=0.1,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        T_max=256,\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=256,\n",
      "        eta_min=0,\n",
      "        type='CosineAnnealingLR'),\n",
      "]\n",
      "randomness = dict(deterministic=False, diff_rank_seed=False, seed=None)\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='data/video_fpha/fpha_val.txt',\n",
      "        data_prefix=dict(video='data/video_fpha/val'),\n",
      "        pipeline=[\n",
      "            dict(io_backend='disk', type='DecordInit'),\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=10,\n",
      "                test_mode=True,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=256, type='ThreeCrop'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='VideoDataset'),\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(type='AccMetric')\n",
      "test_pipeline = [\n",
      "    dict(io_backend='disk', type='DecordInit'),\n",
      "    dict(\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=10,\n",
      "        test_mode=True,\n",
      "        type='SampleFrames'),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=256, type='ThreeCrop'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_epochs=128, type='EpochBasedTrainLoop', val_begin=1, val_interval=5)\n",
      "train_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        ann_file='data/video_fpha/fpha_train.txt',\n",
      "        data_prefix=dict(video='data/video_fpha/train'),\n",
      "        pipeline=[\n",
      "            dict(io_backend='disk', type='DecordInit'),\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(keep_ratio=False, scale=(\n",
      "                224,\n",
      "                224,\n",
      "            ), type='Resize'),\n",
      "            dict(flip_ratio=0.5, type='Flip'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        type='VideoDataset'),\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(io_backend='disk', type='DecordInit'),\n",
      "    dict(clip_len=32, frame_interval=2, num_clips=1, type='SampleFrames'),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(keep_ratio=False, scale=(\n",
      "        224,\n",
      "        224,\n",
      "    ), type='Resize'),\n",
      "    dict(flip_ratio=0.5, type='Flip'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        ann_file='data/video_fpha/fpha_val.txt',\n",
      "        data_prefix=dict(video='data/video_fpha/val'),\n",
      "        pipeline=[\n",
      "            dict(io_backend='disk', type='DecordInit'),\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                test_mode=True,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=224, type='CenterCrop'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='VideoDataset'),\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(type='AccMetric')\n",
      "val_pipeline = [\n",
      "    dict(io_backend='disk', type='DecordInit'),\n",
      "    dict(\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=1,\n",
      "        test_mode=True,\n",
      "        type='SampleFrames'),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=224, type='CenterCrop'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='ActionVisualizer', vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs/slowfast_fpha'\n",
      "\n",
      "08/06 08:27:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "08/06 08:27:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "Loads checkpoint by local backend from path: ./checkpoints/slowfast_fpha.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for cls_head.fc_cls.weight: copying a param with shape torch.Size([400, 2304]) from checkpoint, the shape in current model is torch.Size([46, 2304]).\n",
      "size mismatch for cls_head.fc_cls.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([46]).\n",
      "08/06 08:27:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from ./checkpoints/slowfast_fpha.pth\n",
      "08/06 08:27:06 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "08/06 08:27:06 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "08/06 08:27:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /root/autodl-tmp/mmaction2/work_dirs/slowfast_fpha.\n",
      "08/06 08:27:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][100/235]  lr: 1.1115e-02  eta: 2:56:26  time: 0.3023  data_time: 0.0133  memory: 3308  grad_norm: 5.6495  loss: 3.7051  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.7051\n",
      "08/06 08:28:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][200/235]  lr: 1.2242e-02  eta: 2:43:35  time: 0.3003  data_time: 0.0096  memory: 3308  grad_norm: 7.2374  loss: 3.2693  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.2693\n",
      "08/06 08:28:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 08:28:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][235/235]  lr: 1.2636e-02  eta: 2:41:38  time: 0.3097  data_time: 0.0125  memory: 3308  grad_norm: 8.2432  loss: 3.2297  top1_acc: 0.0000  top5_acc: 0.6667  loss_cls: 3.2297\n",
      "08/06 08:28:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][100/235]  lr: 1.3762e-02  eta: 2:37:47  time: 0.2971  data_time: 0.0112  memory: 3308  grad_norm: 8.4783  loss: 3.0860  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.0860\n",
      "08/06 08:29:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][200/235]  lr: 1.4889e-02  eta: 2:34:21  time: 0.2764  data_time: 0.0087  memory: 3308  grad_norm: 7.4667  loss: 3.0092  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 3.0092\n",
      "08/06 08:29:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 08:29:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][235/235]  lr: 1.5283e-02  eta: 2:33:32  time: 0.2944  data_time: 0.0099  memory: 3308  grad_norm: 7.0322  loss: 2.7623  top1_acc: 0.0000  top5_acc: 0.3333  loss_cls: 2.7623\n",
      "08/06 08:30:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][100/235]  lr: 1.6408e-02  eta: 2:31:59  time: 0.2963  data_time: 0.0102  memory: 3308  grad_norm: 7.0605  loss: 2.7960  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 2.7960\n",
      "08/06 08:30:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][200/235]  lr: 1.7534e-02  eta: 2:30:24  time: 0.2934  data_time: 0.0072  memory: 3308  grad_norm: 7.1097  loss: 2.5908  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 2.5908\n",
      "08/06 08:30:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 08:30:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][235/235]  lr: 1.7928e-02  eta: 2:29:54  time: 0.2934  data_time: 0.0116  memory: 3308  grad_norm: 6.6262  loss: 2.6817  top1_acc: 0.0000  top5_acc: 0.6667  loss_cls: 2.6817\n",
      "08/06 08:31:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][100/235]  lr: 1.9051e-02  eta: 2:28:53  time: 0.2943  data_time: 0.0077  memory: 3308  grad_norm: 6.7344  loss: 2.6620  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.6620\n",
      "08/06 08:31:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][200/235]  lr: 2.0177e-02  eta: 2:26:53  time: 0.2825  data_time: 0.0078  memory: 3308  grad_norm: 4.9521  loss: 2.5620  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 2.5620\n",
      "08/06 08:31:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 08:31:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][235/235]  lr: 2.0571e-02  eta: 2:26:32  time: 0.2886  data_time: 0.0072  memory: 3308  grad_norm: 6.4627  loss: 2.2233  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 2.2233\n",
      "08/06 08:31:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 4 epochs\n",
      "08/06 08:32:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 08:32:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][100/235]  lr: 2.1692e-02  eta: 2:25:56  time: 0.2962  data_time: 0.0100  memory: 3308  grad_norm: 5.9047  loss: 2.5444  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 2.5444\n",
      "08/06 08:32:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][200/235]  lr: 2.2818e-02  eta: 2:25:10  time: 0.2948  data_time: 0.0095  memory: 3308  grad_norm: 6.4433  loss: 2.9875  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 2.9875\n",
      "08/06 08:33:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 08:33:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][235/235]  lr: 2.3212e-02  eta: 2:24:54  time: 0.2948  data_time: 0.0096  memory: 3308  grad_norm: 5.1024  loss: 2.4566  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 2.4566\n",
      "08/06 08:33:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [5][59/59]    acc/top1: 0.3559  acc/top5: 0.8093  acc/mean1: 0.3459  data_time: 0.0281  time: 0.1078\n",
      "08/06 08:33:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.3559 acc/top1 at 5 epoch is saved to best_acc_top1_epoch_5.pth.\n",
      "08/06 08:33:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][100/235]  lr: 2.4329e-02  eta: 2:24:12  time: 0.2931  data_time: 0.0073  memory: 3308  grad_norm: 5.6139  loss: 2.6759  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.6759\n",
      "08/06 08:34:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][200/235]  lr: 2.5455e-02  eta: 2:23:32  time: 0.2949  data_time: 0.0076  memory: 3308  grad_norm: 5.3932  loss: 2.3255  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.3255\n",
      "08/06 08:34:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 08:34:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][235/235]  lr: 2.5849e-02  eta: 2:23:16  time: 0.2882  data_time: 0.0083  memory: 3308  grad_norm: 5.2946  loss: 2.5541  top1_acc: 0.0000  top5_acc: 0.6667  loss_cls: 2.5541\n",
      "08/06 08:34:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][100/235]  lr: 2.6963e-02  eta: 2:22:43  time: 0.2922  data_time: 0.0074  memory: 3308  grad_norm: 5.7076  loss: 2.4794  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 2.4794\n",
      "08/06 08:45:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][100/235]  lr: 5.0397e-02  eta: 2:10:44  time: 0.2944  data_time: 0.0078  memory: 3308  grad_norm: 3.9202  loss: 2.1601  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 2.1601\n",
      "08/06 08:45:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][200/235]  lr: 5.1514e-02  eta: 2:10:12  time: 0.2965  data_time: 0.0081  memory: 3308  grad_norm: 3.6095  loss: 1.9357  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.9357\n",
      "08/06 08:46:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 08:46:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][235/235]  lr: 5.1905e-02  eta: 2:10:00  time: 0.2904  data_time: 0.0070  memory: 3308  grad_norm: 4.1638  loss: 2.2645  top1_acc: 0.3333  top5_acc: 0.3333  loss_cls: 2.2645\n",
      "08/06 08:46:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 16 epochs\n",
      "08/06 08:46:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][100/235]  lr: 5.2960e-02  eta: 2:09:32  time: 0.2976  data_time: 0.0108  memory: 3308  grad_norm: 3.7385  loss: 2.0916  top1_acc: 0.0000  top5_acc: 0.7500  loss_cls: 2.0916\n",
      "08/06 08:47:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][200/235]  lr: 5.4076e-02  eta: 2:09:02  time: 0.2916  data_time: 0.0074  memory: 3308  grad_norm: 3.8429  loss: 2.0811  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 2.0811\n",
      "08/06 08:47:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 08:47:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][235/235]  lr: 5.4466e-02  eta: 2:08:51  time: 0.2909  data_time: 0.0085  memory: 3308  grad_norm: 3.7091  loss: 1.9916  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.9916\n",
      "08/06 08:47:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 08:47:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][100/235]  lr: 5.5512e-02  eta: 2:08:21  time: 0.2799  data_time: 0.0099  memory: 3308  grad_norm: 3.7879  loss: 1.9118  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 1.9118\n",
      "08/06 08:48:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][200/235]  lr: 5.6627e-02  eta: 2:07:50  time: 0.2957  data_time: 0.0099  memory: 3308  grad_norm: 3.4789  loss: 1.8846  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.8846\n",
      "08/06 08:48:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 08:48:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][235/235]  lr: 5.7017e-02  eta: 2:07:39  time: 0.2917  data_time: 0.0077  memory: 3308  grad_norm: 3.2866  loss: 1.9550  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 1.9550\n",
      "08/06 08:48:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][100/235]  lr: 5.8054e-02  eta: 2:07:11  time: 0.2956  data_time: 0.0074  memory: 3308  grad_norm: 3.3109  loss: 1.8016  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 1.8016\n",
      "08/06 08:49:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][200/235]  lr: 5.9167e-02  eta: 2:06:41  time: 0.2946  data_time: 0.0075  memory: 3308  grad_norm: 4.1879  loss: 2.2077  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.2077\n",
      "08/06 08:49:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 08:49:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][235/235]  lr: 5.9557e-02  eta: 2:06:30  time: 0.2927  data_time: 0.0105  memory: 3308  grad_norm: 3.6395  loss: 2.5435  top1_acc: 0.3333  top5_acc: 0.6667  loss_cls: 2.5435\n",
      "08/06 08:50:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][100/235]  lr: 6.0585e-02  eta: 2:05:48  time: 0.2765  data_time: 0.0077  memory: 3308  grad_norm: 3.3887  loss: 1.9300  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9300\n",
      "08/06 08:50:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][200/235]  lr: 6.1696e-02  eta: 2:05:18  time: 0.2944  data_time: 0.0076  memory: 3308  grad_norm: 3.3034  loss: 1.6438  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 1.6438\n",
      "08/06 08:50:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 08:50:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][235/235]  lr: 6.2085e-02  eta: 2:05:07  time: 0.2943  data_time: 0.0108  memory: 3308  grad_norm: 3.4732  loss: 1.6275  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6275\n",
      "08/06 08:50:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 20 epochs\n",
      "08/06 08:50:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][59/59]    acc/top1: 0.5508  acc/top5: 0.9195  acc/mean1: 0.5741  data_time: 0.0126  time: 0.0932\n",
      "08/06 08:50:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /root/autodl-tmp/mmaction2/work_dirs/slowfast_fpha/best_acc_top1_epoch_15.pth is removed\n",
      "08/06 08:50:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.5508 acc/top1 at 20 epoch is saved to best_acc_top1_epoch_20.pth.\n",
      "08/06 08:51:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][100/235]  lr: 6.3103e-02  eta: 2:04:39  time: 0.2945  data_time: 0.0075  memory: 3308  grad_norm: 3.9396  loss: 2.0656  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.0656\n",
      "08/06 08:51:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][200/235]  lr: 6.4213e-02  eta: 2:04:09  time: 0.2994  data_time: 0.0115  memory: 3308  grad_norm: 3.3681  loss: 1.9292  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 1.9292\n",
      "08/06 08:51:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 08:51:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][235/235]  lr: 6.4601e-02  eta: 2:03:57  time: 0.2950  data_time: 0.0099  memory: 3308  grad_norm: 3.3755  loss: 1.8290  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 1.8290\n",
      "08/06 08:52:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 08:52:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][100/235]  lr: 6.5609e-02  eta: 2:03:29  time: 0.2952  data_time: 0.0077  memory: 3308  grad_norm: 3.7401  loss: 2.1069  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 2.1069\n",
      "08/06 08:52:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][200/235]  lr: 6.6717e-02  eta: 2:02:59  time: 0.2969  data_time: 0.0106  memory: 3308  grad_norm: 3.8379  loss: 1.8787  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 1.8787\n",
      "08/06 08:53:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 08:53:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][235/235]  lr: 6.7105e-02  eta: 2:02:48  time: 0.2948  data_time: 0.0108  memory: 3308  grad_norm: 3.4127  loss: 1.9007  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 1.9007\n",
      "08/06 08:53:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][100/235]  lr: 6.8102e-02  eta: 2:02:19  time: 0.2938  data_time: 0.0075  memory: 3308  grad_norm: 3.1814  loss: 2.0454  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 2.0454\n",
      "08/06 08:54:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][200/235]  lr: 6.9208e-02  eta: 2:01:47  time: 0.2957  data_time: 0.0075  memory: 3308  grad_norm: 3.5839  loss: 1.9595  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.9595\n",
      "08/06 08:54:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 08:54:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][235/235]  lr: 6.9595e-02  eta: 2:01:37  time: 0.2895  data_time: 0.0072  memory: 3308  grad_norm: 3.3656  loss: 1.9602  top1_acc: 0.6667  top5_acc: 0.6667  loss_cls: 1.9602\n",
      "08/06 09:08:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][200/235]  lr: 9.5710e-02  eta: 1:47:40  time: 0.2973  data_time: 0.0077  memory: 3308  grad_norm: 3.0672  loss: 1.8732  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8732\n",
      "08/06 09:08:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 09:08:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][235/235]  lr: 9.5710e-02  eta: 1:47:29  time: 0.2750  data_time: 0.0119  memory: 3308  grad_norm: 2.6137  loss: 1.7068  top1_acc: 0.6667  top5_acc: 0.6667  loss_cls: 1.7068\n",
      "08/06 09:08:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [35][59/59]    acc/top1: 0.6356  acc/top5: 0.9407  acc/mean1: 0.6326  data_time: 0.0185  time: 0.0992\n",
      "08/06 09:08:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /root/autodl-tmp/mmaction2/work_dirs/slowfast_fpha/best_acc_top1_epoch_30.pth is removed\n",
      "08/06 09:08:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.6356 acc/top1 at 35 epoch is saved to best_acc_top1_epoch_35.pth.\n",
      "08/06 09:09:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][100/235]  lr: 9.5458e-02  eta: 1:47:00  time: 0.2932  data_time: 0.0083  memory: 3308  grad_norm: 2.8300  loss: 2.0768  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0768\n",
      "08/06 09:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][200/235]  lr: 9.5458e-02  eta: 1:46:31  time: 0.2951  data_time: 0.0086  memory: 3308  grad_norm: 2.8378  loss: 1.8071  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 1.8071\n",
      "08/06 09:09:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 09:09:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][235/235]  lr: 9.5458e-02  eta: 1:46:20  time: 0.2884  data_time: 0.0074  memory: 3308  grad_norm: 2.6757  loss: 2.1891  top1_acc: 0.6667  top5_acc: 0.6667  loss_cls: 2.1891\n",
      "08/06 09:09:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 36 epochs\n",
      "08/06 09:10:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][100/235]  lr: 9.5199e-02  eta: 1:45:51  time: 0.2804  data_time: 0.0107  memory: 3308  grad_norm: 2.6761  loss: 2.0036  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0036\n",
      "08/06 09:10:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][200/235]  lr: 9.5199e-02  eta: 1:45:22  time: 0.2952  data_time: 0.0074  memory: 3308  grad_norm: 2.5841  loss: 1.6056  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6056\n",
      "08/06 09:10:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 09:10:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][235/235]  lr: 9.5199e-02  eta: 1:45:11  time: 0.2910  data_time: 0.0072  memory: 3308  grad_norm: 2.7253  loss: 2.0953  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 2.0953\n",
      "08/06 09:11:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][100/235]  lr: 9.4934e-02  eta: 1:44:42  time: 0.2926  data_time: 0.0073  memory: 3308  grad_norm: 2.5330  loss: 1.3739  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 1.3739\n",
      "08/06 09:11:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][200/235]  lr: 9.4934e-02  eta: 1:44:13  time: 0.2934  data_time: 0.0080  memory: 3308  grad_norm: 3.0786  loss: 2.3020  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.3020\n",
      "08/06 09:37:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][100/235]  lr: 8.7457e-02  eta: 1:19:10  time: 0.2972  data_time: 0.0083  memory: 3308  grad_norm: 2.3062  loss: 1.1996  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.1996\n",
      "08/06 09:37:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 09:39:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][100/235]  lr: 8.6633e-02  eta: 1:16:51  time: 0.2954  data_time: 0.0082  memory: 3308  grad_norm: 2.4979  loss: 1.3774  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 1.3774\n",
      "08/06 09:40:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][200/235]  lr: 8.6633e-02  eta: 1:16:21  time: 0.2969  data_time: 0.0101  memory: 3308  grad_norm: 2.6977  loss: 1.5023  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 1.5023\n",
      "08/06 09:40:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 09:40:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][235/235]  lr: 8.6633e-02  eta: 1:16:11  time: 0.2914  data_time: 0.0076  memory: 3308  grad_norm: 2.1027  loss: 1.1941  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1941\n",
      "08/06 09:40:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][100/235]  lr: 8.6212e-02  eta: 1:15:42  time: 0.2754  data_time: 0.0079  memory: 3308  grad_norm: 2.3790  loss: 1.0870  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 1.0870\n",
      "08/06 09:41:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][200/235]  lr: 8.6212e-02  eta: 1:15:12  time: 0.2959  data_time: 0.0076  memory: 3308  grad_norm: 2.1678  loss: 1.0050  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.0050\n",
      "08/06 09:41:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 09:41:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][235/235]  lr: 8.6212e-02  eta: 1:15:02  time: 0.2920  data_time: 0.0077  memory: 3308  grad_norm: 2.3184  loss: 1.0147  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 1.0147\n",
      "08/06 09:41:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][100/235]  lr: 8.5787e-02  eta: 1:14:33  time: 0.2966  data_time: 0.0078  memory: 3308  grad_norm: 2.4619  loss: 1.2014  top1_acc: 0.7500  top5_acc: 0.7500  loss_cls: 1.2014\n",
      "08/06 09:42:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 09:42:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][200/235]  lr: 8.5787e-02  eta: 1:14:03  time: 0.2927  data_time: 0.0077  memory: 3308  grad_norm: 2.4914  loss: 1.4878  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.4878\n",
      "08/06 09:42:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 09:42:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][235/235]  lr: 8.5787e-02  eta: 1:13:53  time: 0.2921  data_time: 0.0076  memory: 3308  grad_norm: 2.4901  loss: 1.2602  top1_acc: 0.0000  top5_acc: 0.6667  loss_cls: 1.2602\n",
      "08/06 09:42:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 64 epochs\n",
      "08/06 09:43:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][100/235]  lr: 8.5355e-02  eta: 1:13:24  time: 0.2959  data_time: 0.0075  memory: 3308  grad_norm: 2.3190  loss: 1.1068  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 1.1068\n",
      "08/06 09:43:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][200/235]  lr: 8.5355e-02  eta: 1:12:54  time: 0.2953  data_time: 0.0086  memory: 3308  grad_norm: 2.5859  loss: 1.2936  top1_acc: 0.7500  top5_acc: 0.7500  loss_cls: 1.2936\n",
      "08/06 09:43:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 09:43:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][235/235]  lr: 8.5355e-02  eta: 1:12:44  time: 0.2922  data_time: 0.0074  memory: 3308  grad_norm: 2.4915  loss: 1.3741  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 1.3741\n",
      "08/06 09:43:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [65][59/59]    acc/top1: 0.6229  acc/top5: 0.9661  acc/mean1: 0.6337  data_time: 0.0125  time: 0.0930\n",
      "08/06 09:44:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][100/235]  lr: 8.4919e-02  eta: 1:12:15  time: 0.3021  data_time: 0.0116  memory: 3308  grad_norm: 2.5917  loss: 1.3817  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.3817\n",
      "08/06 09:44:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][200/235]  lr: 8.4919e-02  eta: 1:11:44  time: 0.3000  data_time: 0.0079  memory: 3308  grad_norm: 2.6186  loss: 1.6376  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6376\n",
      "08/06 09:45:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 09:45:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][235/235]  lr: 8.4919e-02  eta: 1:11:33  time: 0.2917  data_time: 0.0073  memory: 3308  grad_norm: 2.0075  loss: 0.9603  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.9603\n",
      "08/06 09:45:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][100/235]  lr: 8.4477e-02  eta: 1:11:04  time: 0.2966  data_time: 0.0075  memory: 3308  grad_norm: 2.4974  loss: 1.3701  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 1.3701\n",
      "08/06 09:46:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][200/235]  lr: 8.4477e-02  eta: 1:10:35  time: 0.2912  data_time: 0.0071  memory: 3308  grad_norm: 2.2885  loss: 1.2784  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 1.2784\n",
      "08/06 09:46:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 09:46:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][235/235]  lr: 8.4477e-02  eta: 1:10:24  time: 0.2900  data_time: 0.0073  memory: 3308  grad_norm: 2.7050  loss: 1.4283  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 1.4283\n",
      "08/06 09:46:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][100/235]  lr: 8.4030e-02  eta: 1:09:55  time: 0.2942  data_time: 0.0078  memory: 3308  grad_norm: 2.2326  loss: 1.1009  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.1009\n",
      "08/06 09:47:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][200/235]  lr: 8.4030e-02  eta: 1:09:26  time: 0.2948  data_time: 0.0076  memory: 3308  grad_norm: 2.1466  loss: 1.2832  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 1.2832\n",
      "08/06 09:47:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 09:47:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][235/235]  lr: 8.4030e-02  eta: 1:09:15  time: 0.2916  data_time: 0.0085  memory: 3308  grad_norm: 1.9351  loss: 1.1451  top1_acc: 0.6667  top5_acc: 0.6667  loss_cls: 1.1451\n",
      "08/06 09:47:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 68 epochs\n",
      "08/06 09:47:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 09:47:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][100/235]  lr: 8.3578e-02  eta: 1:08:46  time: 0.2970  data_time: 0.0096  memory: 3308  grad_norm: 2.2054  loss: 0.9427  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.9427\n",
      "08/06 09:48:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][200/235]  lr: 8.3578e-02  eta: 1:08:17  time: 0.2967  data_time: 0.0078  memory: 3308  grad_norm: 2.3488  loss: 1.2920  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.2920\n",
      "08/06 09:48:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 09:48:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][235/235]  lr: 8.3578e-02  eta: 1:08:06  time: 0.2900  data_time: 0.0076  memory: 3308  grad_norm: 2.4183  loss: 1.1176  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 1.1176\n",
      "08/06 09:48:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][100/235]  lr: 8.3121e-02  eta: 1:07:32  time: 0.1496  data_time: 0.0079  memory: 3308  grad_norm: 2.4398  loss: 1.2871  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.2871\n",
      "08/06 09:49:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][200/235]  lr: 8.3121e-02  eta: 1:06:50  time: 0.1509  data_time: 0.0086  memory: 3308  grad_norm: 2.6165  loss: 1.4300  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 1.4300\n",
      "08/06 09:49:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 09:49:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][235/235]  lr: 8.3121e-02  eta: 1:06:36  time: 0.1475  data_time: 0.0083  memory: 3308  grad_norm: 2.3979  loss: 1.2702  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2702\n",
      "08/06 09:49:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [70][59/59]    acc/top1: 0.6864  acc/top5: 0.9619  acc/mean1: 0.7133  data_time: 0.0127  time: 0.0520\n",
      "08/06 09:49:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /root/autodl-tmp/mmaction2/work_dirs/slowfast_fpha/best_acc_top1_epoch_55.pth is removed\n",
      "08/06 09:49:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.6864 acc/top1 at 70 epoch is saved to best_acc_top1_epoch_70.pth.\n",
      "08/06 09:49:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][100/235]  lr: 8.2659e-02  eta: 1:05:55  time: 0.1507  data_time: 0.0089  memory: 3308  grad_norm: 2.4499  loss: 1.2755  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.2755\n",
      "08/06 09:49:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][200/235]  lr: 8.2659e-02  eta: 1:05:14  time: 0.1559  data_time: 0.0126  memory: 3308  grad_norm: 2.4592  loss: 1.0700  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 1.0700\n",
      "08/06 09:49:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 09:49:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][235/235]  lr: 8.2659e-02  eta: 1:05:00  time: 0.1465  data_time: 0.0072  memory: 3308  grad_norm: 2.2143  loss: 1.1382  top1_acc: 0.0000  top5_acc: 0.6667  loss_cls: 1.1382\n",
      "08/06 09:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][100/235]  lr: 8.2192e-02  eta: 1:04:20  time: 0.1492  data_time: 0.0079  memory: 3308  grad_norm: 2.4194  loss: 1.3290  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3290\n",
      "08/06 09:50:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][200/235]  lr: 8.2192e-02  eta: 1:03:40  time: 0.1495  data_time: 0.0078  memory: 3308  grad_norm: 2.6405  loss: 1.4022  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4022\n",
      "08/06 09:50:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 09:50:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][235/235]  lr: 8.2192e-02  eta: 1:03:26  time: 0.1473  data_time: 0.0077  memory: 3308  grad_norm: 2.3117  loss: 1.2335  top1_acc: 0.6667  top5_acc: 0.6667  loss_cls: 1.2335\n",
      "08/06 09:50:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 72 epochs\n",
      "08/06 09:50:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 09:50:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][100/235]  lr: 8.1720e-02  eta: 1:02:47  time: 0.1494  data_time: 0.0076  memory: 3308  grad_norm: 2.1606  loss: 1.0952  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.0952\n",
      "08/06 09:51:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][200/235]  lr: 8.1720e-02  eta: 1:02:08  time: 0.1487  data_time: 0.0077  memory: 3308  grad_norm: 2.4889  loss: 1.2725  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2725\n",
      "08/06 09:51:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 09:51:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][235/235]  lr: 8.1720e-02  eta: 1:01:54  time: 0.1514  data_time: 0.0106  memory: 3308  grad_norm: 2.2655  loss: 1.0149  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.0149\n",
      "08/06 09:51:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][100/235]  lr: 8.1243e-02  eta: 1:01:15  time: 0.1498  data_time: 0.0084  memory: 3308  grad_norm: 2.1717  loss: 0.9914  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.9914\n",
      "08/06 09:51:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][200/235]  lr: 8.1243e-02  eta: 1:00:37  time: 0.1494  data_time: 0.0079  memory: 3308  grad_norm: 2.7496  loss: 1.3006  top1_acc: 0.7500  top5_acc: 0.7500  loss_cls: 1.3006\n",
      "08/06 09:51:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 09:51:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][235/235]  lr: 8.1243e-02  eta: 1:00:23  time: 0.1472  data_time: 0.0074  memory: 3308  grad_norm: 2.7060  loss: 1.2045  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 1.2045\n",
      "08/06 09:51:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][100/235]  lr: 8.0762e-02  eta: 0:59:45  time: 0.1488  data_time: 0.0071  memory: 3308  grad_norm: 2.8798  loss: 1.6083  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 1.6083\n",
      "08/06 09:52:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][200/235]  lr: 8.0762e-02  eta: 0:59:07  time: 0.1490  data_time: 0.0073  memory: 3308  grad_norm: 2.3482  loss: 1.2580  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 1.2580\n",
      "08/06 09:52:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 09:52:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][235/235]  lr: 8.0762e-02  eta: 0:58:54  time: 0.1469  data_time: 0.0074  memory: 3308  grad_norm: 2.3853  loss: 1.4105  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 1.4105\n",
      "08/06 09:52:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [75][59/59]    acc/top1: 0.7797  acc/top5: 0.9661  acc/mean1: 0.7790  data_time: 0.0126  time: 0.0510\n",
      "08/06 09:52:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /root/autodl-tmp/mmaction2/work_dirs/slowfast_fpha/best_acc_top1_epoch_70.pth is removed\n",
      "08/06 09:52:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.7797 acc/top1 at 75 epoch is saved to best_acc_top1_epoch_75.pth.\n",
      "08/06 09:52:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][100/235]  lr: 8.0276e-02  eta: 0:58:17  time: 0.1625  data_time: 0.0186  memory: 3308  grad_norm: 2.2406  loss: 1.3389  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.3389\n",
      "08/06 09:52:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][200/235]  lr: 8.0276e-02  eta: 0:57:41  time: 0.1592  data_time: 0.0161  memory: 3308  grad_norm: 2.2409  loss: 0.9196  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.9196\n",
      "08/06 09:53:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 09:53:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][235/235]  lr: 8.0276e-02  eta: 0:57:28  time: 0.1562  data_time: 0.0144  memory: 3308  grad_norm: 2.6620  loss: 1.2134  top1_acc: 0.3333  top5_acc: 0.6667  loss_cls: 1.2134\n",
      "08/06 09:53:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 76 epochs\n",
      "08/06 09:53:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][100/235]  lr: 7.9785e-02  eta: 0:56:51  time: 0.1716  data_time: 0.0153  memory: 3308  grad_norm: 2.8469  loss: 1.1947  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.1947\n",
      "08/06 09:53:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 09:53:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][200/235]  lr: 7.9785e-02  eta: 0:56:15  time: 0.1585  data_time: 0.0148  memory: 3308  grad_norm: 2.2405  loss: 1.0557  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.0557\n",
      "08/06 09:53:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 09:53:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][235/235]  lr: 7.9785e-02  eta: 0:56:02  time: 0.1533  data_time: 0.0120  memory: 3308  grad_norm: 2.4370  loss: 1.1085  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1085\n",
      "08/06 10:03:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][200/235]  lr: 7.1378e-02  eta: 0:35:47  time: 0.1606  data_time: 0.0159  memory: 3308  grad_norm: 2.4386  loss: 1.2392  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.2392\n",
      "08/06 10:03:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:03:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][235/235]  lr: 7.1378e-02  eta: 0:35:37  time: 0.1568  data_time: 0.0154  memory: 3308  grad_norm: 2.5731  loss: 1.1633  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 1.1633\n",
      "08/06 10:04:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][100/235]  lr: 7.0821e-02  eta: 0:35:07  time: 0.1578  data_time: 0.0140  memory: 3308  grad_norm: 2.5930  loss: 1.2555  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2555\n",
      "08/06 10:04:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:04:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][200/235]  lr: 7.0821e-02  eta: 0:34:37  time: 0.1577  data_time: 0.0143  memory: 3308  grad_norm: 2.2643  loss: 1.0681  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.0681\n",
      "08/06 10:04:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:04:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][235/235]  lr: 7.0821e-02  eta: 0:34:27  time: 0.1544  data_time: 0.0127  memory: 3308  grad_norm: 2.1829  loss: 0.8124  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.8124\n",
      "08/06 10:04:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][100/235]  lr: 7.0262e-02  eta: 0:33:58  time: 0.1577  data_time: 0.0151  memory: 3308  grad_norm: 1.8593  loss: 0.6580  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6580\n",
      "08/06 10:05:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][200/235]  lr: 7.0262e-02  eta: 0:33:28  time: 0.1572  data_time: 0.0141  memory: 3308  grad_norm: 2.4201  loss: 1.0459  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0459\n",
      "08/06 10:05:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:05:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][235/235]  lr: 7.0262e-02  eta: 0:33:18  time: 0.1546  data_time: 0.0137  memory: 3308  grad_norm: 2.9710  loss: 1.4956  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 1.4956\n",
      "08/06 10:05:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [95][59/59]    acc/top1: 0.6949  acc/top5: 0.9661  acc/mean1: 0.7099  data_time: 0.0171  time: 0.0568\n",
      "08/06 10:05:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][100/235]  lr: 6.9700e-02  eta: 0:32:49  time: 0.1570  data_time: 0.0139  memory: 3308  grad_norm: 2.0034  loss: 0.8804  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 0.8804\n",
      "08/06 10:05:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][200/235]  lr: 6.9700e-02  eta: 0:32:20  time: 0.1588  data_time: 0.0151  memory: 3308  grad_norm: 1.9524  loss: 0.9871  top1_acc: 0.7500  top5_acc: 0.7500  loss_cls: 0.9871\n",
      "08/06 10:05:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:05:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][235/235]  lr: 6.9700e-02  eta: 0:32:10  time: 0.1565  data_time: 0.0153  memory: 3308  grad_norm: 2.0532  loss: 0.9505  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.9505\n",
      "08/06 10:05:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 96 epochs\n",
      "08/06 10:06:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][100/235]  lr: 6.9134e-02  eta: 0:31:41  time: 0.1596  data_time: 0.0155  memory: 3308  grad_norm: 2.6031  loss: 1.0138  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.0138\n",
      "08/06 10:06:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][200/235]  lr: 6.9134e-02  eta: 0:31:12  time: 0.1623  data_time: 0.0171  memory: 3308  grad_norm: 2.5998  loss: 1.1429  top1_acc: 0.7500  top5_acc: 0.7500  loss_cls: 1.1429\n",
      "08/06 10:06:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:06:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][235/235]  lr: 6.9134e-02  eta: 0:31:02  time: 0.1526  data_time: 0.0106  memory: 3308  grad_norm: 2.5579  loss: 0.9901  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 0.9901\n",
      "08/06 10:06:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][100/235]  lr: 6.8566e-02  eta: 0:30:34  time: 0.1563  data_time: 0.0133  memory: 3308  grad_norm: 2.3137  loss: 0.8254  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8254\n",
      "08/06 10:07:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][200/235]  lr: 6.8566e-02  eta: 0:30:05  time: 0.1585  data_time: 0.0154  memory: 3308  grad_norm: 2.4498  loss: 1.0292  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 1.0292\n",
      "08/06 10:07:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:07:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:07:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][235/235]  lr: 6.8566e-02  eta: 0:29:55  time: 0.1548  data_time: 0.0144  memory: 3308  grad_norm: 2.8456  loss: 1.2876  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2876\n",
      "08/06 10:07:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][100/235]  lr: 6.7995e-02  eta: 0:29:27  time: 0.1568  data_time: 0.0131  memory: 3308  grad_norm: 2.2993  loss: 1.0150  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.0150\n",
      "08/06 10:07:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][200/235]  lr: 6.7995e-02  eta: 0:28:59  time: 0.1587  data_time: 0.0154  memory: 3308  grad_norm: 2.3765  loss: 0.8689  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.8689\n",
      "08/06 10:07:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:07:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][235/235]  lr: 6.7995e-02  eta: 0:28:49  time: 0.1554  data_time: 0.0145  memory: 3308  grad_norm: 2.6862  loss: 1.1032  top1_acc: 0.0000  top5_acc: 0.6667  loss_cls: 1.1032\n",
      "08/06 10:08:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][100/235]  lr: 6.7421e-02  eta: 0:28:21  time: 0.1583  data_time: 0.0149  memory: 3308  grad_norm: 2.3478  loss: 0.9439  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.9439\n",
      "08/06 10:08:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][200/235]  lr: 6.7421e-02  eta: 0:27:53  time: 0.1586  data_time: 0.0156  memory: 3308  grad_norm: 3.1239  loss: 1.4066  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4066\n",
      "08/06 10:08:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:08:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][235/235]  lr: 6.7421e-02  eta: 0:27:43  time: 0.1550  data_time: 0.0130  memory: 3308  grad_norm: 2.5509  loss: 1.0543  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 1.0543\n",
      "08/06 10:08:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 100 epochs\n",
      "08/06 10:08:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [100][59/59]    acc/top1: 0.7542  acc/top5: 0.9661  acc/mean1: 0.7763  data_time: 0.0181  time: 0.0579\n",
      "08/06 10:08:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][100/235]  lr: 6.6844e-02  eta: 0:27:15  time: 0.1592  data_time: 0.0152  memory: 3308  grad_norm: 2.7204  loss: 1.2129  top1_acc: 0.7500  top5_acc: 0.7500  loss_cls: 1.2129\n",
      "08/06 10:09:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][200/235]  lr: 6.6844e-02  eta: 0:26:47  time: 0.1566  data_time: 0.0133  memory: 3308  grad_norm: 2.0370  loss: 0.8538  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8538\n",
      "08/06 10:09:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:09:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][235/235]  lr: 6.6844e-02  eta: 0:26:38  time: 0.1566  data_time: 0.0152  memory: 3308  grad_norm: 2.3351  loss: 0.9214  top1_acc: 0.3333  top5_acc: 0.6667  loss_cls: 0.9214\n",
      "08/06 10:09:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][100/235]  lr: 6.6266e-02  eta: 0:26:10  time: 0.1583  data_time: 0.0150  memory: 3308  grad_norm: 2.5104  loss: 1.0458  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0458\n",
      "08/06 10:09:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][200/235]  lr: 6.6266e-02  eta: 0:25:42  time: 0.1563  data_time: 0.0136  memory: 3308  grad_norm: 2.1825  loss: 0.7857  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7857\n",
      "08/06 10:09:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:09:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][235/235]  lr: 6.6266e-02  eta: 0:25:33  time: 0.1549  data_time: 0.0140  memory: 3308  grad_norm: 2.3461  loss: 1.1106  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 1.1106\n",
      "08/06 10:09:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:10:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][100/235]  lr: 6.5684e-02  eta: 0:25:05  time: 0.1570  data_time: 0.0145  memory: 3308  grad_norm: 2.2884  loss: 0.8905  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.8905\n",
      "08/06 10:10:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][200/235]  lr: 6.5684e-02  eta: 0:24:38  time: 0.1592  data_time: 0.0165  memory: 3308  grad_norm: 2.0369  loss: 0.7292  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7292\n",
      "08/06 10:10:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:10:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][235/235]  lr: 6.5684e-02  eta: 0:24:29  time: 0.1568  data_time: 0.0153  memory: 3308  grad_norm: 2.5340  loss: 1.0462  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.0462\n",
      "08/06 10:10:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][100/235]  lr: 6.5100e-02  eta: 0:24:01  time: 0.1567  data_time: 0.0139  memory: 3308  grad_norm: 2.7666  loss: 1.2824  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2824\n",
      "08/06 10:10:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][200/235]  lr: 6.5100e-02  eta: 0:23:34  time: 0.1550  data_time: 0.0121  memory: 3308  grad_norm: 2.7723  loss: 0.9153  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.9153\n",
      "08/06 10:10:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:10:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][235/235]  lr: 6.5100e-02  eta: 0:23:25  time: 0.1571  data_time: 0.0160  memory: 3308  grad_norm: 2.4296  loss: 0.8299  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.8299\n",
      "08/06 10:10:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 104 epochs\n",
      "08/06 10:11:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][100/235]  lr: 6.4514e-02  eta: 0:22:58  time: 0.1584  data_time: 0.0150  memory: 3308  grad_norm: 2.2426  loss: 1.1039  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.1039\n",
      "08/06 10:11:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][200/235]  lr: 6.4514e-02  eta: 0:22:31  time: 0.1525  data_time: 0.0089  memory: 3308  grad_norm: 2.4286  loss: 0.8934  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8934\n",
      "08/06 10:11:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:11:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][235/235]  lr: 6.4514e-02  eta: 0:22:22  time: 0.1528  data_time: 0.0117  memory: 3308  grad_norm: 2.0776  loss: 0.9125  top1_acc: 0.3333  top5_acc: 0.6667  loss_cls: 0.9125\n",
      "08/06 10:11:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [105][59/59]    acc/top1: 0.8008  acc/top5: 0.9915  acc/mean1: 0.8175  data_time: 0.0186  time: 0.0587\n",
      "08/06 10:11:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /root/autodl-tmp/mmaction2/work_dirs/slowfast_fpha/best_acc_top1_epoch_75.pth is removed\n",
      "08/06 10:11:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.8008 acc/top1 at 105 epoch is saved to best_acc_top1_epoch_105.pth.\n",
      "08/06 10:11:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][100/235]  lr: 6.3926e-02  eta: 0:21:55  time: 0.1574  data_time: 0.0155  memory: 3308  grad_norm: 2.0479  loss: 0.9168  top1_acc: 0.7500  top5_acc: 0.7500  loss_cls: 0.9168\n",
      "08/06 10:12:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][200/235]  lr: 6.3926e-02  eta: 0:21:28  time: 0.1563  data_time: 0.0129  memory: 3308  grad_norm: 2.2951  loss: 0.9546  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.9546\n",
      "08/06 10:12:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:12:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][235/235]  lr: 6.3926e-02  eta: 0:21:19  time: 0.1551  data_time: 0.0146  memory: 3308  grad_norm: 2.3060  loss: 0.8697  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.8697\n",
      "08/06 10:12:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:12:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][100/235]  lr: 6.3336e-02  eta: 0:20:52  time: 0.1565  data_time: 0.0142  memory: 3308  grad_norm: 2.1971  loss: 0.8006  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.8006\n",
      "08/06 10:12:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][200/235]  lr: 6.3336e-02  eta: 0:20:26  time: 0.1621  data_time: 0.0170  memory: 3308  grad_norm: 2.0219  loss: 0.7159  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7159\n",
      "08/06 10:12:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:12:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][235/235]  lr: 6.3336e-02  eta: 0:20:17  time: 0.1526  data_time: 0.0120  memory: 3308  grad_norm: 1.9624  loss: 0.7146  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 0.7146\n",
      "08/06 10:13:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][100/235]  lr: 6.2743e-02  eta: 0:19:50  time: 0.1586  data_time: 0.0159  memory: 3308  grad_norm: 2.0435  loss: 0.6910  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6910\n",
      "08/06 10:13:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][200/235]  lr: 6.2743e-02  eta: 0:19:24  time: 0.1567  data_time: 0.0140  memory: 3308  grad_norm: 2.6038  loss: 0.8897  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.8897\n",
      "08/06 10:13:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:13:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][235/235]  lr: 6.2743e-02  eta: 0:19:15  time: 0.1537  data_time: 0.0132  memory: 3308  grad_norm: 1.9680  loss: 0.7446  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7446\n",
      "08/06 10:13:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 108 epochs\n",
      "08/06 10:13:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][100/235]  lr: 6.2149e-02  eta: 0:18:49  time: 0.1569  data_time: 0.0142  memory: 3308  grad_norm: 2.0389  loss: 0.8835  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.8835\n",
      "08/06 10:14:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][200/235]  lr: 6.2149e-02  eta: 0:18:22  time: 0.1575  data_time: 0.0148  memory: 3308  grad_norm: 2.5327  loss: 1.0496  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.0496\n",
      "08/06 10:14:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:14:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][235/235]  lr: 6.2149e-02  eta: 0:18:13  time: 0.1538  data_time: 0.0130  memory: 3308  grad_norm: 2.5317  loss: 1.0209  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.0209\n",
      "08/06 10:14:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][100/235]  lr: 6.1553e-02  eta: 0:17:47  time: 0.1560  data_time: 0.0135  memory: 3308  grad_norm: 2.0419  loss: 0.8375  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8375\n",
      "08/06 10:14:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][200/235]  lr: 6.1553e-02  eta: 0:17:21  time: 0.1562  data_time: 0.0133  memory: 3308  grad_norm: 2.3673  loss: 1.0291  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 1.0291\n",
      "08/06 10:14:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:14:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][235/235]  lr: 6.1553e-02  eta: 0:17:12  time: 0.1536  data_time: 0.0134  memory: 3308  grad_norm: 1.8984  loss: 0.7019  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7019\n",
      "08/06 10:14:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [110][59/59]    acc/top1: 0.8008  acc/top5: 0.9831  acc/mean1: 0.7911  data_time: 0.0184  time: 0.0580\n",
      "08/06 10:15:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][100/235]  lr: 6.0955e-02  eta: 0:16:47  time: 0.1576  data_time: 0.0152  memory: 3308  grad_norm: 2.0469  loss: 0.6542  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6542\n",
      "08/06 10:15:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:15:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][200/235]  lr: 6.0955e-02  eta: 0:16:21  time: 0.1574  data_time: 0.0139  memory: 3308  grad_norm: 2.0511  loss: 0.8346  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8346\n",
      "08/06 10:15:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:15:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][235/235]  lr: 6.0955e-02  eta: 0:16:12  time: 0.1546  data_time: 0.0138  memory: 3308  grad_norm: 1.9736  loss: 0.8297  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.8297\n",
      "08/06 10:15:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][100/235]  lr: 6.0356e-02  eta: 0:15:46  time: 0.1589  data_time: 0.0156  memory: 3308  grad_norm: 2.2318  loss: 0.9011  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 0.9011\n",
      "08/06 10:16:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][200/235]  lr: 6.0356e-02  eta: 0:15:21  time: 0.1589  data_time: 0.0163  memory: 3308  grad_norm: 2.3018  loss: 0.9871  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.9871\n",
      "08/06 10:16:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:16:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][235/235]  lr: 6.0356e-02  eta: 0:15:12  time: 0.1552  data_time: 0.0143  memory: 3308  grad_norm: 2.3492  loss: 0.9585  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.9585\n",
      "08/06 10:16:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 112 epochs\n",
      "08/06 10:16:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][100/235]  lr: 5.9755e-02  eta: 0:14:46  time: 0.1565  data_time: 0.0137  memory: 3308  grad_norm: 2.0805  loss: 0.8015  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.8015\n",
      "08/06 10:16:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][200/235]  lr: 5.9755e-02  eta: 0:14:21  time: 0.1557  data_time: 0.0132  memory: 3308  grad_norm: 2.4734  loss: 0.9182  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.9182\n",
      "08/06 10:16:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:16:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][235/235]  lr: 5.9755e-02  eta: 0:14:12  time: 0.1530  data_time: 0.0122  memory: 3308  grad_norm: 2.4158  loss: 0.8447  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.8447\n",
      "08/06 10:17:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][100/235]  lr: 5.9152e-02  eta: 0:13:47  time: 0.1573  data_time: 0.0148  memory: 3308  grad_norm: 2.3963  loss: 1.0004  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.0004\n",
      "08/06 10:17:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][200/235]  lr: 5.9152e-02  eta: 0:13:22  time: 0.1567  data_time: 0.0147  memory: 3308  grad_norm: 1.8093  loss: 0.5781  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5781\n",
      "08/06 10:17:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:17:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][235/235]  lr: 5.9152e-02  eta: 0:13:13  time: 0.1564  data_time: 0.0156  memory: 3308  grad_norm: 2.2353  loss: 0.7602  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.7602\n",
      "08/06 10:17:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][100/235]  lr: 5.8548e-02  eta: 0:12:48  time: 0.1579  data_time: 0.0155  memory: 3308  grad_norm: 2.1012  loss: 0.7251  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7251\n",
      "08/06 10:17:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][200/235]  lr: 5.8548e-02  eta: 0:12:23  time: 0.1560  data_time: 0.0133  memory: 3308  grad_norm: 2.3367  loss: 1.1606  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 1.1606\n",
      "08/06 10:17:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:18:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:18:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][235/235]  lr: 5.8548e-02  eta: 0:12:14  time: 0.1513  data_time: 0.0107  memory: 3308  grad_norm: 2.8390  loss: 1.0249  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 1.0249\n",
      "08/06 10:18:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [115][59/59]    acc/top1: 0.7924  acc/top5: 0.9788  acc/mean1: 0.8040  data_time: 0.0163  time: 0.0559\n",
      "08/06 10:23:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][200/235]  lr: 5.3678e-02  eta: 0:04:44  time: 0.1557  data_time: 0.0130  memory: 3308  grad_norm: 2.3049  loss: 0.8245  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8245\n",
      "08/06 10:23:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:23:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][235/235]  lr: 5.3678e-02  eta: 0:04:36  time: 0.1539  data_time: 0.0135  memory: 3308  grad_norm: 2.2278  loss: 0.8151  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.8151\n",
      "08/06 10:23:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:23:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][100/235]  lr: 5.3066e-02  eta: 0:04:12  time: 0.1574  data_time: 0.0148  memory: 3308  grad_norm: 2.1675  loss: 0.6631  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6631\n",
      "08/06 10:23:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][200/235]  lr: 5.3066e-02  eta: 0:03:48  time: 0.1567  data_time: 0.0137  memory: 3308  grad_norm: 2.3861  loss: 0.9887  top1_acc: 0.7500  top5_acc: 0.7500  loss_cls: 0.9887\n",
      "08/06 10:23:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:23:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][235/235]  lr: 5.3066e-02  eta: 0:03:40  time: 0.1529  data_time: 0.0121  memory: 3308  grad_norm: 2.2909  loss: 0.8777  top1_acc: 0.6667  top5_acc: 0.6667  loss_cls: 0.8777\n",
      "08/06 10:23:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 124 epochs\n",
      "08/06 10:24:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][100/235]  lr: 5.2453e-02  eta: 0:03:16  time: 0.1555  data_time: 0.0131  memory: 3308  grad_norm: 2.0885  loss: 0.7664  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7664\n",
      "08/06 10:24:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][200/235]  lr: 5.2453e-02  eta: 0:02:53  time: 0.1553  data_time: 0.0133  memory: 3308  grad_norm: 2.6363  loss: 0.7835  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7835\n",
      "08/06 10:24:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:24:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][235/235]  lr: 5.2453e-02  eta: 0:02:44  time: 0.1553  data_time: 0.0142  memory: 3308  grad_norm: 2.6831  loss: 0.8828  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.8828\n",
      "08/06 10:24:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [125][59/59]    acc/top1: 0.7627  acc/top5: 0.9661  acc/mean1: 0.7928  data_time: 0.0181  time: 0.0578\n",
      "08/06 10:24:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][100/235]  lr: 5.1840e-02  eta: 0:02:21  time: 0.1552  data_time: 0.0130  memory: 3308  grad_norm: 2.2364  loss: 0.6362  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6362\n",
      "08/06 10:25:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][200/235]  lr: 5.1840e-02  eta: 0:01:57  time: 0.1563  data_time: 0.0139  memory: 3308  grad_norm: 2.0948  loss: 0.8660  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8660\n",
      "08/06 10:25:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowfast_fpha_20230806_082658\n",
      "08/06 10:25:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][235/235]  lr: 5.1840e-02  eta: 0:01:49  time: 0.1547  data_time: 0.0133  memory: 3308  grad_norm: 1.5605  loss: 0.5560  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.5560\n",
      "08/06 10:25:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][100/235]  lr: 5.1227e-02  eta: 0:01:26  time: 0.1585  data_time: 0.0158  memory: 3308  grad_norm: 2.2987  loss: 0.9436  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 0.9436\n"
     ]
    }
   ],
   "source": [
    "!python tools/train.py ./configs/egocentric/slowfast_fpha.py; /usr/bin/shutdown "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360556c7-2bde-4f02-b5f3-bc0e0bcef2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
